### CoGenAV: Contrastive-Generative Audio-Visual Representation Learning  
**Code and models will be open-sourced soon!**  

---

#### ðŸš€ Project Overview  
CoGenAV is a framework for audio-visual representation learning based on **Contrastive-Generative Synchronization**, designed to learn efficient and generalizable audio-visual representations through multimodal alignment of speech, lip movements, and text. The model performs exceptionally well across multiple audio-visual tasks, including:  
- **Audio-Visual Speech Recognition (AVSR)**  
- **Visual Speech Recognition (VSR)**  
- **Audio-Visual Speech Enhancement and Separation (AVSE/AVSS)**  
- **Active Speaker Detection (ASD)**  

---

#### ðŸŒŸ Key Advantages  
1. **Efficient Learning**: High-performance models can be trained with only **223 hours of labeled data** (from the LRS2 dataset).  
2. **Cross-Task Generalizability**: Unified representation learning allows direct adaptation to various downstream tasks without task-specific architectural adjustments.  
3. **Robustness**: Performance improves by **70%+** in noisy environments (0 dB SNR), significantly outperforming traditional audio-only models.  
